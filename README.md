# AI-Document-Intelligence-Pipeline-PDF-Structured-JSONL-for-Multimodal-RAG-
A robust, production-grade pipeline converting complex Medical PDFs into structured, RAG-ready JSONL datasets. Features smart table merging, multimodal extraction, and dynamic layout analysis using Detectron2 &amp; PaddleOCR.
Plaintext

Medical-RAG-Pipeline/
â”‚
â”œâ”€â”€ input_data/                  # (Auto-created) Yahan apni PDF books rakhein
â”‚   â”œâ”€â”€ Batch_01/
â”‚   â”‚   â”œâ”€â”€ book1.pdf
â”‚   â”‚   â””â”€â”€ book2.pdf
â”‚   â””â”€â”€ Batch_02/
â”‚
â”œâ”€â”€ output_data/                 # (Auto-created) Processed JSONL aur Images yahan aayenge
â”‚   â”œâ”€â”€ book1/
â”‚   â”‚   â”œâ”€â”€ structured_output.jsonl
â”‚   â”‚   â””â”€â”€ images/
â”‚
â”œâ”€â”€ logs/                        # (Auto-created) Execution logs yahan save honge
â”‚
â”œâ”€â”€ models/                      # (Optional) Agar manual model download karke rakhne ho
â”‚
â”œâ”€â”€ extract_batch.py             # ğŸ§  MAIN BRAIN: Orchestrator script (Plan 18)
â”œâ”€â”€ validate_setup.py            # ğŸ›  TOOL: Environment checker (GPU/Libs)
â”œâ”€â”€ warm_cache_models.py         # ğŸ“¥ SETUP: Models ko pehli baar download karne ke liye
â”œâ”€â”€ requirements_extra.txt       # ğŸ“‹ LIST: Sabhi libraries ki list
â”œâ”€â”€ install_detectron2_manual.sh # ğŸš SCRIPT: Detectron2 install helper
â”‚
â””â”€â”€ README.md                    # ğŸ“– GUIDE: Jo hum niche likh rahe hain
2. Professional GitHub README.md
Is content ko copy karke README.md file bana lo. Maine "Models Download" aur "YouTube Video" wale section wese hi daale hain jaise tumne kaha tha.

Markdown

# ğŸ¥ Medical Book Extraction Pipeline for RAG (Plan 18)

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-2.3%2B-red)
![Status](https://img.shields.io/badge/Pipeline-Production%20Ready-success)
![GPU](https://img.shields.io/badge/GPU-Required-orange)

An advanced, industrial-grade pipeline designed to convert complex Medical Textbooks (PDFs) into structured **JSONL** format suitable for **RAG (Retrieval-Augmented Generation)** models. 

This project implements **"Plan 18" architecture**, featuring Smart Table Merging, Dynamic Header/Footer detection, and Multi-Model Cross-Validation (LayoutParser + Table Transformer + PaddleOCR).

---

## âš¡ Key Features

* **ğŸ“„ Intelligent Layout Analysis:** Uses **Detectron2 (PubLayNet)** to segment pages into Text, Tables, Figures, and Lists.
* **ğŸ“Š Smart Table Extraction:** Implements an **IoU-based Smart Merging** algorithm to reconstruct tables accurately using **Microsoft Table Transformer**.
* **ğŸ§  Dynamic Filtering:** Automatically detects and removes Headers and Footers based on recurring patterns in the book.
* **ğŸ‘ï¸ High-Quality OCR:** Powered by **PaddleOCR (GPU)** for robust text extraction from images and non-selectable PDFs.
* **ğŸ›¡ï¸ Robustness:** Includes checkpointing (resume where you left off) and detailed logging.

---

## ğŸ› ï¸ Prerequisites

Before starting, ensure your system meets these requirements:

1.  **OS:** Linux (Recommended) or Windows with WSL2.
2.  **GPU:** NVIDIA GPU with CUDA 12.1 support (Required for efficient processing).
3.  **Python:** Version 3.8 or higher.
4.  **System Libraries:** `libstdc++` (Modern version required for OCR).

---

## ğŸš€ Installation Guide (Step-by-Step)

Follow these steps strictly to set up the environment.

### 1. Clone the Repository
```bash
git clone [https://github.com/YOUR_USERNAME/Medical-RAG-Pipeline.git](https://github.com/YOUR_USERNAME/Medical-RAG-Pipeline.git)
cd Medical-RAG-Pipeline
2. Create Virtual Environment
Bash

python -m venv venv
source venv/bin/activate  # On Windows use: venv\Scripts\activate
3. Install Core Dependencies
We have a curated requirements file. Install it using pip:

Bash

pip install -r requirements_extra.txt
4. Install Detectron2 (Crucial Step)
Detectron2 can be tricky. If the command above fails for Detectron2, use our manual script:

Bash

chmod +x install_detectron2_manual.sh
./install_detectron2_manual.sh
ğŸ“¥ Model Setup (First Time Run)
This pipeline uses large models (LayoutParser, Table Transformer, PaddleOCR). Instead of downloading them during runtime, run the warmer script first to download and cache them locally.

Run this command once:

Bash

python warm_cache_models.py
This script will download all necessary weights to ~/.torch/ and ~/.paddleocr/ directories.

âœ… Validate Setup
Before running the main processor, run the validation tool to check if GPU, CUDA, and Libraries are linked correctly:

Bash

python validate_setup.py
If you see "âœ… VALIDATION COMPLETE", you are ready to go!

â–¶ï¸ How to Run
1. Prepare Input Data
Create a folder named input_data and add your PDF files inside batch folders:

Plaintext

input_data/
    Batch_01/
        Anatomy_Book.pdf
        Physiology.pdf
2. Start Processing
Run the main orchestrator script:

Bash

python extract_batch.py
3. Check Outputs
The script will generate an output_data folder.

JSONL: Contains the structured text and metadata.

Images: Contains extracted figures/charts cropped from the pages.

ğŸ¥ Video Tutorial
Click the image below to watch the complete step-by-step setup and demo video on YouTube.

(Note: The video demonstrates how to configure the paths and interprets the JSONL output.)

ğŸ“„ Output Structure (JSONL)
Each line in the output file represents a single element (Text block, Table, or Image):

JSON

{
  "type": "Table",
  "page_number": 45,
  "coordinates": [100, 200, 500, 600],
  "confidence": 0.98,
  "text": "Full text content of the table...",
  "html_table": "<table><tr><td>Cell Data</td>...</table>"
}
ğŸ“ Contact & Support
For issues or contributions, please open an issue in this repository.

Maintainer: [Your Name]
